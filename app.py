import os
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="ржмрж╛ржВрж▓рж╛ FAQ ржЪрзНржпрж╛ржЯржмржЯ",
    page_icon="ЁЯдЦ",
    layout="wide"
)

# Initialize session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# Setup Embeddings
@st.cache_resource
def load_embedding_model():
    """Load the Bengali embedding model"""
    return HuggingFaceEmbeddings(model_name="l3cube-pune/bengali-sentence-similarity-sbert")

# Prepare FAQ Dataset with Metadata
def prepare_faq_data():
    """Prepare FAQ chunks with metadata for 5 Bangla topics"""
    
    # рж╢рж┐ржХрзНрж╖рж╛ (Education)
    education_chunks = [
        ("ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝рзЗ ржнрж░рзНрждрж┐рж░ ржЬржирзНржп ржПрж╕ржПрж╕рж╕рж┐ ржПржмржВ ржПржЗржЪржПрж╕рж╕рж┐рждрзЗ ржнрж╛рж▓рзЛ ржлрж▓рж╛ржлрж▓ ржкрзНрж░ржпрж╝рзЛржЬржиред", 
         {"category": "рж╢рж┐ржХрзНрж╖рж╛", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржЕржирж▓рж╛ржЗржи ржХрзЛрж░рзНрж╕ ржХрж░рж╛рж░ ржЬржирзНржп ржЗржирзНржЯрж╛рж░ржирзЗржЯ рж╕ржВржпрзЛржЧ ржПржмржВ ржПржХржЯрж┐ ржбрж┐ржнрж╛ржЗрж╕ рж▓рж╛ржЧржмрзЗред", 
         {"category": "рж╢рж┐ржХрзНрж╖рж╛", "difficulty":  "рж╕рж╣ржЬ"}),
        ("рж╕рзНржХрзБрж▓рзЗ ржнрж░рзНрждрж┐рж░ ржЬржирзНржп ржЬржирзНржо ржирж┐ржмржирзНржзржи рж╕ржиржж ржкрзНрж░ржпрж╝рзЛржЬржиред", 
         {"category": "рж╢рж┐ржХрзНрж╖рж╛", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржЙржЪрзНржЪрж╢рж┐ржХрзНрж╖рж╛рж░ ржЬржирзНржп рж╕рзНржХрж▓рж╛рж░рж╢рж┐ржк ржкрзЗрждрзЗ ржнрж╛рж▓рзЛ ржПржХрж╛ржбрзЗржорж┐ржХ рж░рзЗржХрж░рзНржб ржерж╛ржХрждрзЗ рж╣ржмрзЗред", 
         {"category": "рж╢рж┐ржХрзНрж╖рж╛", "difficulty":  "ржорж╛ржЭрж╛рж░рж┐"}),
        ("ржмрж┐ржжрзЗрж╢рзЗ ржкржбрж╝рж╛рж╢рзЛржирж╛рж░ ржЬржирзНржп IELTS ржмрж╛ TOEFL рж╕рзНржХрзЛрж░ ржкрзНрж░ржпрж╝рзЛржЬржи рж╣рждрзЗ ржкрж╛рж░рзЗред", 
         {"category": "рж╢рж┐ржХрзНрж╖рж╛", "difficulty": "ржорж╛ржЭрж╛рж░рж┐"}),
    ]
    
    # рж╕рзНржмрж╛рж╕рзНржерзНржп (Health)
    health_chunks = [
        ("рж╕рж░рзНржжрж┐-ржХрж╛рж╢рж┐рж░ ржЬржирзНржп ржЧрж░ржо ржкрж╛ржирж┐ ржкрж╛ржи ржПржмржВ ржмрж┐рж╢рзНрж░рж╛ржо ржирж┐ржиред", 
         {"category": "рж╕рзНржмрж╛рж╕рзНржерзНржп", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржкрзНрж░рждрж┐ржжрж┐ржи ржХржоржкржХрзНрж╖рзЗ рзо ржЧрзНрж▓рж╛рж╕ ржкрж╛ржирж┐ ржкрж╛ржи ржХрж░рж╛ ржЙржЪрж┐рждред", 
         {"category": "рж╕рзНржмрж╛рж╕рзНржерзНржп", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржЬрзНржмрж░ рж╣рж▓рзЗ ржкрзНржпрж╛рж░рж╛рж╕рж┐ржЯрж╛ржорж▓ ржЦрж╛ржУржпрж╝рж╛ ржпрзЗрждрзЗ ржкрж╛рж░рзЗ рждржмрзЗ ржбрж╛ржХрзНрждрж╛рж░рзЗрж░ ржкрж░рж╛ржорж░рзНрж╢ ржирж┐ржиред", 
         {"category": "рж╕рзНржмрж╛рж╕рзНржерзНржп", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржирж┐ржпрж╝ржорж┐ржд ржмрзНржпрж╛ржпрж╝рж╛ржо рж╢рж░рзАрж░ рж╕рзБрж╕рзНрже рж░рж╛ржЦрждрзЗ рж╕рж╛рж╣рж╛ржпрзНржп ржХрж░рзЗред", 
         {"category": "рж╕рзНржмрж╛рж╕рзНржерзНржп", "difficulty": "рж╕рж╣ржЬ"}),
        ("рж░ржХрзНрждржЪрж╛ржк ржирж┐ржпрж╝ржирзНрждрзНрж░ржгрзЗ рж░рж╛ржЦрждрзЗ рж▓ржмржг ржХржо ржЦрж╛ржи ржПржмржВ рж╕рзНржЯрзНрж░рзЗрж╕ ржХржорж╛ржиред", 
         {"category": "рж╕рзНржмрж╛рж╕рзНржерзНржп", "difficulty":  "ржорж╛ржЭрж╛рж░рж┐"}),
    ]
    
    # ржнрзНрж░ржоржг (Travel)
    travel_chunks = [
        ("ржХржХрзНрж╕ржмрж╛ржЬрж╛рж░ ржнрзНрж░ржоржгрзЗрж░ ржЬржирзНржп ржкрзНрж░рж╛ржпрж╝ рззрзл-рзирзж рж╣рж╛ржЬрж╛рж░ ржЯрж╛ржХрж╛ ржмрж╛ржЬрзЗржЯ рж░рж╛ржЦрзБржиред", 
         {"category": "ржнрзНрж░ржоржг", "difficulty": "рж╕рж╣ржЬ"}),
        ("рж╕рзБржирзНржжрж░ржмржи ржпрзЗрждрзЗ рж╣рж▓рзЗ ржЦрзБрж▓ржирж╛ ржмрж╛ рж╕рж╛рждржХрзНрж╖рзАрж░рж╛ ржерзЗржХрзЗ ржмрзЛржЯрзЗ ржпрзЗрждрзЗ рж╣ржмрзЗред", 
         {"category": "ржнрзНрж░ржоржг", "difficulty": "рж╕рж╣ржЬ"}),
        ("рж╕рж┐рж▓рзЗржЯрзЗрж░ ржЬрж╛ржлрж▓ржВ ржПржмржВ рж░рж╛рждрж╛рж░ржЧрзБрж▓ ржЦрзБржм рж╕рзБржирзНржжрж░ ржкрж░рзНржпржЯржи рж╕рзНржерж╛ржиред", 
         {"category": "ржнрзНрж░ржоржг", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржкрж╛рж╕ржкрзЛрж░рзНржЯ ржХрж░рждрзЗ ржЕржирж▓рж╛ржЗржирзЗ ржЖржмрзЗржжржи ржХрж░рзЗ ржлрж┐ ржЬржорж╛ ржжрж┐рждрзЗ рж╣ржпрж╝ред", 
         {"category": "ржнрзНрж░ржоржг", "difficulty": "ржорж╛ржЭрж╛рж░рж┐"}),
        ("ржмрж┐ржжрзЗрж╢ ржнрзНрж░ржоржгрзЗрж░ ржЬржирзНржп ржнрж┐рж╕рж╛ ржкрзНрж░ржпрж╝рзЛржЬржи рж╣рждрзЗ ржкрж╛рж░рзЗ, ржжрзЗрж╢ржнрзЗржжрзЗ ржнрж┐ржирзНржиред", 
         {"category": "ржнрзНрж░ржоржг", "difficulty": "ржорж╛ржЭрж╛рж░рж┐"}),
    ]
    
    # ржкрзНрж░ржпрзБржХрзНрждрж┐ (Technology)
    technology_chunks = [
        ("рж╕рзНржорж╛рж░рзНржЯржлрзЛржирзЗрж░ ржмрзНржпрж╛ржЯрж╛рж░рж┐ ржмрж╛ржБржЪрж╛рждрзЗ ржмрзНрж░рж╛ржЗржЯржирзЗрж╕ ржХржорж╛ржи ржПржмржВ ржЕржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝ ржЕрзНржпрж╛ржк ржмржирзНржз ржХрж░рзБржиред", 
         {"category": "ржкрзНрж░ржпрзБржХрзНрждрж┐", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржЗржирзНржЯрж╛рж░ржирзЗржЯ рж╕рзНржкрж┐ржб ржмрж╛ржбрж╝рж╛рждрзЗ рж░рж╛ржЙржЯрж╛рж░ рж░рж┐рж╕рзНржЯрж╛рж░рзНржЯ ржжрж┐ржи ржПржмржВ рж╕ржарж┐ржХ рж╕рзНржерж╛ржирзЗ рж░рж╛ржЦрзБржиред", 
         {"category": "ржкрзНрж░ржпрзБржХрзНрждрж┐", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржХржорзНржкрж┐ржЙржЯрж╛рж░ рж╕рзНрж▓рзЛ рж╣рж▓рзЗ ржЕржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝ ржлрж╛ржЗрж▓ ржбрж┐рж▓рж┐ржЯ ржХрж░рзБржи ржПржмржВ ржЕрзНржпрж╛ржирзНржЯрж┐ржнрж╛ржЗрж░рж╛рж╕ ржЪрж╛рж▓рж╛ржиред", 
         {"category": "ржкрзНрж░ржпрзБржХрзНрждрж┐", "difficulty":  "рж╕рж╣ржЬ"}),
        ("ржУржпрж╝рж╛ржЗржлрж╛ржЗ ржкрж╛рж╕ржУржпрж╝рж╛рж░рзНржб рж╕рзБрж░ржХрзНрж╖рж┐ржд рж░рж╛ржЦрждрзЗ рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА ржкрж╛рж╕ржУржпрж╝рж╛рж░рзНржб ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржиред", 
         {"category":  "ржкрзНрж░ржпрзБржХрзНрждрж┐", "difficulty": "ржорж╛ржЭрж╛рж░рж┐"}),
        ("ржбрзЗржЯрж╛ ржмрзНржпрж╛ржХржЖржк ржирж┐рждрзЗ ржХрзНрж▓рж╛ржЙржб рж╕рзНржЯрзЛрж░рзЗржЬ ржпрзЗржоржи ржЧрзБржЧрж▓ ржбрзНрж░рж╛ржЗржн ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржиред", 
         {"category": "ржкрзНрж░ржпрзБржХрзНрждрж┐", "difficulty": "ржорж╛ржЭрж╛рж░рж┐"}),
    ]
    
    # ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛ (Sports)
    sports_chunks = [
        ("ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ рзирзжрзжрзж рж╕рж╛рж▓рзЗ ICC ржЯрзНрж░ржлрж┐ ржЬрж┐рждрзЗржЫрж┐рж▓ред", 
         {"category": "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржХрзНрж░рж┐ржХрзЗржЯ ржЦрзЗрж▓рждрзЗ ржмрзНржпрж╛ржЯ, ржмрж▓ ржПржмржВ ржЙржЗржХрзЗржЯ ржкрзНрж░ржпрж╝рзЛржЬржиред", 
         {"category": "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛", "difficulty": "рж╕рж╣ржЬ"}),
        ("ржлрзБржЯржмрж▓рзЗ рззрзз ржЬржи ржЦрзЗрж▓рзЛржпрж╝рж╛ржбрж╝ ржкрзНрж░рждрж┐ ржжрж▓рзЗ ржерж╛ржХрзЗред", 
         {"category": "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛", "difficulty":  "рж╕рж╣ржЬ"}),
        ("рж╢рж╛ржХрж┐ржм ржЖрж▓ рж╣рж╛рж╕рж╛ржи ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ рж╕рзЗрж░рж╛ ржЕрж▓рж░рж╛ржЙржирзНржбрж╛рж░ ржХрзНрж░рж┐ржХрзЗржЯрж╛рж░ред", 
         {"category":  "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛", "difficulty": "рж╕рж╣ржЬ"}),
        ("рзирзжрзирзи рж╕рж╛рж▓рзЗрж░ ржлрж┐ржлрж╛ ржмрж┐рж╢рзНржмржХрж╛ржк ржЖрж░рзНржЬрзЗржирзНржЯрж┐ржирж╛ ржЬрж┐рждрзЗржЫрзЗред", 
         {"category":  "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛", "difficulty": "ржорж╛ржЭрж╛рж░рж┐"}),
    ]
    
    # Combine all chunks
    all_chunks = (education_chunks + health_chunks + travel_chunks + 
                  technology_chunks + sports_chunks)
    
    return all_chunks

# Create Vector Store
@st.cache_resource
def create_vector_store():
    """Create FAISS vector store from FAQ data"""
    embedding_model = load_embedding_model()
    all_chunks = prepare_faq_data()
    
    documents = [Document(page_content=text, metadata=meta) 
                 for text, meta in all_chunks]
    
    vector_store = FAISS.from_documents(documents, embedding_model)
    return vector_store, documents

# Metadata Filter Function
def filter_by_metadata(query, category, documents, embedding_model):
    """Filter vector store by category metadata and perform similarity search"""
    st.write(f"**ЁЯФН ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐ ржлрж┐рж▓рзНржЯрж╛рж░:** {category}")
    
    # Filter documents by category
    filtered_docs = [doc for doc in documents 
                     if doc.metadata['category'] == category]
    
    if not filtered_docs:
        st.warning(f"'{category}' ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐рждрзЗ ржХрзЛржирзЛ ржбрзЗржЯрж╛ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ржирж┐ред")
        return []
    
    st.write(f"**ЁЯУЪ ржорзЛржЯ {len(filtered_docs)} ржЯрж┐ ржбржХрзБржорзЗржирзНржЯ ржкрж╛ржУржпрж╝рж╛ ржЧрзЗржЫрзЗ**")
    
    # Create temporary vector store with filtered documents
    temp_vector_store = FAISS.from_documents(filtered_docs, embedding_model)
    
    # Perform similarity search
    similar_docs = temp_vector_store.similarity_search(query, k=3)
    
    return similar_docs

# --- Setup OpenAI Client ---
def setup_openai_client():
    """Setup OpenAI client with GitHub Models"""
    token = os.getenv('GITHUB_TOKEN')
    if not token:
        st.error("NO GITHUB_TOKEN in . env")
        return None
    
    endpoint = "https://models.github.ai/inference"
    model = "openai/gpt-4.1-nano"
    
    client = OpenAI(
        base_url=endpoint,
        api_key=token,
    )
    
    return client, model

# Category Router
def detect_category_llm(question, client, model):
    """Use LLM to automatically detect category from question"""
    system_msg = """рждрзБржорж┐ ржПржХржЯрж┐ рж╢рзНрж░рзЗржгрж┐ржмрж┐ржирзНржпрж╛рж╕ржХрж╛рж░рзА ржПржЬрзЗржирзНржЯред ржирж┐ржЪрзЗрж░ ржкрзНрж░рж╢рзНржиржЯрж┐ ржкржбрж╝рзЗ ржмрж▓рзЛ ржПржЯрж┐ ржХрзЛржи ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐рждрзЗ ржкржбрж╝рзЗред

    ржЕржирзБржорзЛржжрж┐ржд ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐: 
    - рж╢рж┐ржХрзНрж╖рж╛ (рж╢рж┐ржХрзНрж╖рж╛, рж╕рзНржХрзБрж▓, ржХрж▓рзЗржЬ, ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝, ржкржбрж╝рж╛рж╢рзЛржирж╛ рж╕ржорзНржкрж░рзНржХрж┐ржд)
    - рж╕рзНржмрж╛рж╕рзНржерзНржп (рж╕рзНржмрж╛рж╕рзНржерзНржп, рж░рзЛржЧ, ржЪрж┐ржХрж┐рзОрж╕рж╛, ржУрж╖рзБржз, ржкрзБрж╖рзНржЯрж┐ рж╕ржорзНржкрж░рзНржХрж┐ржд)
    - ржнрзНрж░ржоржг (ржнрзНрж░ржоржг, ржкрж░рзНржпржЯржи, рж╕рзНржерж╛ржи, ржпрж╛рждрж╛ржпрж╝рж╛ржд рж╕ржорзНржкрж░рзНржХрж┐ржд)
    - ржкрзНрж░ржпрзБржХрзНрждрж┐ (ржХржорзНржкрж┐ржЙржЯрж╛рж░, ржорзЛржмрж╛ржЗрж▓, ржЗржирзНржЯрж╛рж░ржирзЗржЯ, рж╕ржлржЯржУржпрж╝рзНржпрж╛рж░ рж╕ржорзНржкрж░рзНржХрж┐ржд)
    - ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛ (ржХрзНрж░рж┐ржХрзЗржЯ, ржлрзБржЯржмрж▓, ржЦрзЗрж▓рж╛, ржЦрзЗрж▓рзЛржпрж╝рж╛ржбрж╝ рж╕ржорзНржкрж░рзНржХрж┐ржд)
    
    ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржирж┐ржпрж╝ржо:
    - ржпржжрж┐ ржкрзНрж░рж╢рзНржиржЯрж┐ ржЙржкрж░рзЗрж░ ржХрзЛржирзЛ ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐рждрзЗ рж╕рзНржкрж╖рзНржЯржнрж╛ржмрзЗ ржирж╛ ржорж┐рж▓рзЗ, рждрж╛рж╣рж▓рзЗ 'ржЕржирзНржпрж╛ржирзНржп' ржмрж▓рзЛред
    - ржПрж▓рзЛржорзЗрж▓рзЛ рж╢ржмрзНржж, ржЕрж░рзНржерж╣рзАржи ржкрзНрж░рж╢рзНржи, ржмрж╛ ржЕржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ ржкрзНрж░рж╢рзНржирзЗрж░ ржЬржирзНржп 'ржЕржирзНржпрж╛ржирзНржп' ржмрж▓рзЛред
    - рж╢рзБржзрзБржорж╛рждрзНрж░ ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐рж░ ржирж╛ржо ржмрж╛ржВрж▓рж╛ржпрж╝ ржПржХ рж╢ржмрзНржжрзЗ ржЙрждрзНрждрж░ ржжрж╛ржУред
    - рж╕ржирзНржжрзЗрж╣ ржерж╛ржХрж▓рзЗ 'ржЕржирзНржпрж╛ржирзНржп' ржмрж▓рзЛред"""
    
    try:
        response = client.chat.completions. create(
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": question}
            ],
            model=model,
            temperature=0,  # More deterministic
            top_p=1.0
        )
        category = response.choices[0].message.content.strip()
        
        # Validate the returned category
        valid_categories = ["рж╢рж┐ржХрзНрж╖рж╛", "рж╕рзНржмрж╛рж╕рзНржерзНржп", "ржнрзНрж░ржоржг", "ржкрзНрж░ржпрзБржХрзНрждрж┐", "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛", "ржЕржирзНржпрж╛ржирзНржп"]
        
        # Check if response is in valid categories
        if category not in valid_categories:
            st.warning(f"ржЕржирзНржпрж╛ржирзНржп ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐ ржкрж╛ржУржпрж╝рж╛ ржЧрзЗржЫрзЗ: '{category}'. ржбрж┐ржлрж▓рзНржЯ рж╣рж┐рж╕рзЗржмрзЗ 'ржЕржирзНржпрж╛ржирзНржп' ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗред")
            return "ржЕржирзНржпрж╛ржирзНржп"
        
        return category
        
    except Exception as e:  
        st.error(f"ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐ рж╕ржирж╛ржХрзНрждржХрж░ржгрзЗ рж╕ржорж╕рзНржпрж╛: {e}")
        return "ржЕржирзНржпрж╛ржирзНржп"

# RAG Chain
def ask_faq_bot(user_question, category, documents, embedding_model, client, model):
    """Main RAG function to answer questions"""
    # Filter and retrieve similar documents
    docs = filter_by_metadata(user_question, category, documents, embedding_model)
    
    if not docs:
        return "ржжрзБржГржЦрж┐ржд, ржПржЗ ржмрж┐рж╖ржпрж╝рзЗ ржЖржорж╛рж░ ржХрж╛ржЫрзЗ рждржерзНржп ржирзЗржЗред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЕржирзНржп ржкрзНрж░рж╢рзНржи ржХрж░рзБржиред", []
    
    # Create context from retrieved documents
    context = "\n". join([doc.page_content for doc in docs])
    
    # Display retrieved context
    with st.expander("ЁЯУД ржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ рждржерзНржп ржжрзЗржЦрзБржи"):
        for i, doc in enumerate(docs, 1):
            st.write(f"{i}. {doc.page_content}")
    
    # Generate answer using LLM
    try:
        response = client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": f"""рждрзБржорж┐ ржПржХржЬржи рж╕рж╣рж╛ржпрж╝ржХ ржмрж╛ржВрж▓рж╛ рж╕рж╣ржХрж╛рж░рзАред рж╢рзБржзрзБржорж╛рждрзНрж░ ржирж┐ржЪрзЗрж░ ржкрзНрж░рж╛рж╕ржЩрзНржЧрж┐ржХ рждржерзНржп ржерзЗржХрзЗ ржЙрждрзНрждрж░ ржжрж╛ржУред 
                    ржпржжрж┐ ржкрзНрж░рж╢рзНржирзЗрж░ ржЙрждрзНрждрж░ ржкрзНрж░рж╕ржЩрзНржЧрзЗ ржирж╛ ржерж╛ржХрзЗ, ржмрж▓рзЛ 'ржжрзБржГржЦрж┐ржд, ржПржЗ ржмрж┐рж╖ржпрж╝рзЗ ржЖржорж╛рж░ ржЬрж╛ржирж╛ ржирзЗржЗред'
                    
                    ржкрзНрж░рж╕ржЩрзНржЧ: {context}"""
                },
                {
                    "role": "user",
                    "content": user_question,
                }
            ],
            temperature=0.1,
            top_p=0.9,
            model=model
        )
        answer = response.choices[0].message.content
        return answer, docs
    except Exception as e: 
        return f"ржЙрждрзНрждрж░ рждрзИрж░рж┐рждрзЗ рж╕ржорж╕рзНржпрж╛ рж╣ржпрж╝рзЗржЫрзЗ: {e}", docs

# Main Streamlit UI
def main():
    # Header
    st.title("ЁЯдЦ ржмрж╛ржВрж▓рж╛ FAQ ржЪрзНржпрж╛ржЯржмржЯ")
    st.markdown("### RAG-ржнрж┐рждрзНрждрж┐ржХ ржкрзНрж░рж╢рзНржирзЛрждрзНрждрж░ рж╕рж┐рж╕рзНржЯрзЗржо")
    st.markdown("---")
    
    # Load resources
    with st.spinner("ржоржбрзЗрж▓ рж▓рзЛржб рж╣ржЪрзНржЫрзЗ..."):
        embedding_model = load_embedding_model()
        vector_store, documents = create_vector_store()
        openai_setup = setup_openai_client()
        
        if openai_setup is None:
            st.stop()
        
        client, model = openai_setup
    
    # Sidebar
    with st.sidebar:
        st. header("тЪЩя╕П рж╕рзЗржЯрж┐ржВрж╕")
        
        # Category selection mode
        auto_category = st.checkbox("рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐ рж╕ржирж╛ржХрзНрждржХрж░ржг", value=True)
        
        # Manual category selection
        if not auto_category: 
            categories = ["рж╢рж┐ржХрзНрж╖рж╛", "рж╕рзНржмрж╛рж╕рзНржерзНржп", "ржнрзНрж░ржоржг", "ржкрзНрж░ржпрзБржХрзНрждрж┐", "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛"]
            selected_category = st.selectbox("ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи:", categories)
        
        st.markdown("---")
        
        # Example questions
        st.subheader("ЁЯУЭ ржЙржжрж╛рж╣рж░ржг ржкрзНрж░рж╢рзНржи:")
        example_questions = {
            "рж╢рж┐ржХрзНрж╖рж╛": "ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝рзЗ ржнрж░рзНрждрж┐рж░ ржЬржирзНржп ржХрзА ржкрзНрж░ржпрж╝рзЛржЬржи?",
            "рж╕рзНржмрж╛рж╕рзНржерзНржп": "рж░ржХрзНрждржЪрж╛ржк ржирж┐ржпрж╝ржирзНрждрзНрж░ржгрзЗрж░ ржЬржирзНржп ржХрзА ржХрж░ржм?",
            "ржнрзНрж░ржоржг": "ржХржХрзНрж╕ржмрж╛ржЬрж╛рж░рзЗ ржпрзЗрждрзЗ ржХржд ржЦрж░ржЪ рж╣ржмрзЗ?",
            "ржкрзНрж░ржпрзБржХрзНрждрж┐":  "рж╕рзНржорж╛рж░рзНржЯржлрзЛржирзЗрж░ ржмрзНржпрж╛ржЯрж╛рж░рж┐ ржХрзАржнрж╛ржмрзЗ ржмрж╛ржБржЪрж╛ржм?",
            "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛": "ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржХржмрзЗ ICC ржЯрзНрж░ржлрж┐ ржЬрж┐рждрзЗржЫрзЗ?"
        }
        
        for question in example_questions.values():
            st.text(f"тАв {question}")
        
        st.markdown("---")
        
        # Clear chat button
        if st.button("ЁЯЧСя╕П ржЪрзНржпрж╛ржЯ ржорзБржЫрзБржи"):
            st.session_state.chat_history = []
            st. success("ржЪрзНржпрж╛ржЯ ржорзБржЫрзЗ ржлрзЗрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ!")
    
    # Main chat interface
    st.subheader("ЁЯТм ржкрзНрж░рж╢рзНржи ржХрж░рзБржи")
    
    user_question = st.text_input("ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржи рж▓рж┐ржЦрзБржи:", 
                                   placeholder="ржПржЦрж╛ржирзЗ ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржи рж▓рж┐ржЦрзБржи...")
    
    if st.button("ржЙрждрзНрждрж░ ржкрж╛ржи", type="primary"):
        if user_question.strip():
            # Detect category first (outside spinner)
            if auto_category:
                with st.spinner("ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐ рж╕ржирж╛ржХрзНржд ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ..."):
                    detected_category = detect_category_llm(user_question, client, model)
            
                st.info(f"**рж╕ржирж╛ржХрзНрждржХрзГржд ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐:** {detected_category}")
            
                # Check if category is valid (outside spinner)
                valid_categories = ["рж╢рж┐ржХрзНрж╖рж╛", "рж╕рзНржмрж╛рж╕рзНржерзНржп", "ржнрзНрж░ржоржг", "ржкрзНрж░ржпрзБржХрзНрждрж┐", "ржЦрзЗрж▓рж╛ржзрзБрж▓рж╛"]
                if detected_category not in valid_categories:
                    fallback_message = "ржПржЗ ржкрзНрж░рж╢рзНржиржЯрж┐ ржЖржорж╛рж░ ржЬрзНржЮрж╛ржирзЗрж░ ржмрж╛ржЗрж░рзЗред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЕржирзНржп ржкрзНрж░рж╢рзНржи ржХрж░рзБржиред"
                    st.warning(fallback_message)
                
                    # Add to chat history
                    st.session_state.chat_history.append({
                        "question": user_question,
                        "category": detected_category,
                        "answer": fallback_message
                    })
                    # Display chat history before stopping
                    if st.session_state.chat_history:
                        st.markdown("---")
                        st.subheader("ЁЯУЬ ржЪрзНржпрж╛ржЯ ржЗрждрж┐рж╣рж╛рж╕")
        
                        for i, chat in enumerate(reversed(st.session_state.chat_history), 1):
                            with st.expander(f"ржкрзНрж░рж╢рзНржи {i}:  {chat['question'][:50]}... "):
                                st.write(f"**ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐:** {chat['category']}")
                                st.write(f"**ржкрзНрж░рж╢рзНржи:** {chat['question']}")
                                st.write(f"**ржЙрждрзНрждрж░:** {chat['answer']}")
    
                    st.stop()
            
                category = detected_category
            else:   
                category = selected_category
        
            # Get answer
            with st.spinner("ржЙрждрзНрждрж░ ржЦрзБржБржЬржЫрж┐..."):
                answer, retrieved_docs = ask_faq_bot(
                    user_question, category, documents, 
                    embedding_model, client, model
                )
        
            # Display answer
            st.markdown("### ЁЯОп ржЙрждрзНрждрж░:")
            st.success(answer)
        
            # Add to chat history
            st.session_state.chat_history.append({
                "question": user_question,
                "category": category,
                "answer": answer
            })
        else:
            st.warning("ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржПржХржЯрж┐ ржкрзНрж░рж╢рзНржи рж▓рж┐ржЦрзБржиред")
    
    # Display chat history
    if st.session_state.chat_history:
        st.markdown("---")
        st.subheader("ЁЯУЬ ржЪрзНржпрж╛ржЯ ржЗрждрж┐рж╣рж╛рж╕")
        
        for i, chat in enumerate(reversed(st.session_state.chat_history), 1):
            with st.expander(f"ржкрзНрж░рж╢рзНржи {i}:  {chat['question'][: 50]}..."):
                st. write(f"**ржХрзНржпрж╛ржЯрж╛ржЧрж░рж┐:** {chat['category']}")
                st.write(f"**ржкрзНрж░рж╢рзНржи:** {chat['question']}")
                st.write(f"**ржЙрждрзНрждрж░:** {chat['answer']}")

if __name__ == "__main__": 
    main()


